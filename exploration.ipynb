{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata_path = Path('/home/gabriel/data/screenshop_fashionpedia/annotations/instances_attributes_train2020.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_metadata_path) as f:\n",
    "    dataset_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'images', 'info', 'licenses', 'categories', 'attributes'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = {}\n",
    "\n",
    "for image in Path('/home/gabriel/data/screenshop_fashionpedia/raw_images').glob('*'):\n",
    "    ext = image.name.split('.')[-1]\n",
    "    assert ext in ('jpg', 'png')\n",
    "    image_id = int(image.stem)\n",
    "    image_exts[image_id] = ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_images = []\n",
    "\n",
    "for image in dataset_metadata['images']:\n",
    "    image_id = image[\"id\"]\n",
    "    new_filename = f'{image_id:012d}.{image_exts[image_id]}'\n",
    "    \n",
    "    assert (Path('/home/gabriel/data/screenshop_fashionpedia/raw_images') / new_filename).exists(), image\n",
    "    \n",
    "    clean_images.append({\n",
    "        'id': image['id'],\n",
    "        'width': image['width'],\n",
    "        'height': image['height'],\n",
    "        'file_name': new_filename,\n",
    "        'isstatic': image['isstatic'],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_annotations = []\n",
    "\n",
    "for annotation in dataset_metadata['annotations']:\n",
    "    clean_annotations.append({\n",
    "        'id': annotation['id'],\n",
    "        'image_id': annotation['image_id'],\n",
    "        'bbox': annotation['bbox'],\n",
    "        'area': annotation['area'],\n",
    "        'iscrowd': annotation['iscrowd'],\n",
    "        'category_id': annotation['category_id'] + 1,  # must be one-indexed\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(image['id'] for image in clean_images)\n",
    "random.shuffle(ids)\n",
    "\n",
    "train_ids = set(ids[:38_000])\n",
    "val_ids = set(ids[38_000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000 7623\n"
     ]
    }
   ],
   "source": [
    "train_images = [x for x in clean_images if x['id'] in train_ids] \n",
    "val_images = [x for x in clean_images if x['id'] in val_ids] \n",
    "\n",
    "print(len(train_images), len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('/home/gabriel/data/screenshop_fashionpedia/screenshop_train2019').exists():\n",
    "    shutil.rmtree('/home/gabriel/data/screenshop_fashionpedia/screenshop_train2019')\n",
    "\n",
    "if Path('/home/gabriel/data/screenshop_fashionpedia/screenshop_val2019').exists():\n",
    "    shutil.rmtree('/home/gabriel/data/screenshop_fashionpedia/screenshop_val2019')\n",
    "\n",
    "os.makedirs('/home/gabriel/data/screenshop_fashionpedia/screenshop_train2019', exist_ok=True)\n",
    "os.makedirs('/home/gabriel/data/screenshop_fashionpedia/screenshop_val2019', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0716530a80f64055ab1b358751bb4569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=45623.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(clean_images):\n",
    "    from_path = Path('/home/gabriel/data/screenshop_fashionpedia/raw_images') / image['file_name']\n",
    "    to_dir ='screenshop_train2019' if image['id'] in train_ids else 'screenshop_val2019'\n",
    "    to_path = Path('/home/gabriel/data/screenshop_fashionpedia/') / to_dir / image['file_name']\n",
    "    shutil.copyfile(from_path, to_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277780 55621\n"
     ]
    }
   ],
   "source": [
    "train_annotations = [x for x in clean_annotations if x['image_id'] in train_ids] \n",
    "val_annotations = [x for x in clean_annotations if x['image_id'] in val_ids] \n",
    "\n",
    "print(len(train_annotations), len(val_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = {\n",
    "    'annotations': train_annotations,\n",
    "    'images': train_images,\n",
    "    'categories': dataset_metadata['categories'],\n",
    "}\n",
    "\n",
    "val_metadata = {\n",
    "    'annotations': val_annotations,\n",
    "    'images': val_images,\n",
    "    'categories': dataset_metadata['categories'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gabriel/data/screenshop_fashionpedia/annotations/instances_screenshop_train2019.json', 'w') as f:\n",
    "    json.dump(train_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gabriel/data/screenshop_fashionpedia/annotations/instances_screenshop_val2019.json', 'w') as f:\n",
    "    json.dump(val_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
